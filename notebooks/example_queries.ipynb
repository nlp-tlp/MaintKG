{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaintKG Case Study: Using Neo4J Cypher Queries to Address Expert Competency Query\n",
    "![Maintenance](https://img.shields.io/badge/Maintenance-Analysis-blue)\n",
    "![Python](https://img.shields.io/badge/Python-3.9-green)\n",
    "![Neo4j](https://img.shields.io/badge/Neo4j-4.4+-orange)\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates example queries that map to expert competency questions for the MaintKG case study. Through these queries, we explore maintenance patterns, component relationships, and failure analysis within the knowledge graph.\n",
    "\n",
    "### Environment Setup\n",
    "- Python virtual environment activated (`venv`)\n",
    "- Required packages installed (see `requirements.txt`)\n",
    "- Python 3.9 or later\n",
    "\n",
    "### Database Requirements\n",
    "- Neo4j database instance running (version 4.4+)\n",
    "- MaintKG populated with case study data\n",
    "- Valid database credentials configured\n",
    "\n",
    "### Output Information\n",
    "- Plots are automatically saved to `./assets` in PDF format\n",
    "- Query results can be exported to CSV files\n",
    "- Visualizations use matplotlib and seaborn libraries\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "1. [Notebook Setup](#notebook-setup)\n",
    "2. [Cypher Queries](#cypher-queries)\n",
    "    1. [Identification of Failures and Defects](#identification-of-failures-and-defects)\n",
    "    2. [Analysis of Reliability Trends](#analysis-of-reliability-trends-and-benchmarking-of-equipment-performance)\n",
    "    3. [Analysis of Maintenance Costs](#analysis-of-maintenance-costs-and-budget-allocation)\n",
    "    4. [Knowledge Discovery and Management](#knowledge-discovery-and-management)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "from neo4j import GraphDatabase\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the Neo4J connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"<YOUR_USERNAME>\"            # default is \"neo4j\"\n",
    "password = \"<YOUR_PASSWORD>\"            # default is \"neo4j\"\n",
    "database_name = \"<YOUR_DATABASE_NAME>\"  # default is \"neo4j\"\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password), database=database_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(query: str) -> pd.DataFrame:\n",
    "    \"\"\"Fetch data from Neo4j and return a DataFrame.\"\"\"\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        data = result.data()    # Fetch all results    \n",
    "        df = pd.DataFrame(data) # Convert the list of dictionaries to a DataFrame\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cypher Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identification of Failures and Defects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ1. What is the top-n distribution of undesirable states for components on all hydraulic shovels?\n",
    "query_1 = '''\n",
    "MATCH p=(r:Record)-[:MENTIONS]->(n)-[rp:HAS_PATIENT]->(m)-[:MENTIONS]-(r)\n",
    "WHERE id(rp) IN r.relationIds AND labels(n)[0] CONTAINS 'State' AND labels(m)[0] CONTAINS 'Object'\n",
    "WITH r.floc AS asset, n.name AS state, m.name AS component, COUNT(p) AS count\n",
    "WHERE count > 10\n",
    "RETURN asset, state, component, count\n",
    "ORDER BY state, component\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_1_heatmap(query: str, save_path: str = None) -> None:\n",
    "    ''''''\n",
    "    df = fetch_data(query=query)\n",
    "    # Get all unique components and states to ensure all combinations are considered\n",
    "    components = df[\"component\"].unique()\n",
    "    states = df[\"state\"].unique()\n",
    "\n",
    "    # List of unique assets\n",
    "    assets = df[\"asset\"].unique()\n",
    "\n",
    "    # Create a DataFrame that includes all combinations for each asset\n",
    "    all_combinations = pd.DataFrame(\n",
    "        list(product(assets, components, states)), columns=[\"asset\", \"component\", \"state\"]\n",
    "    )\n",
    "\n",
    "    # Merge with original df to include counts\n",
    "    full_df = pd.merge(\n",
    "        all_combinations, df, on=[\"asset\", \"component\", \"state\"], how=\"left\"\n",
    "    ).fillna(0)\n",
    "\n",
    "    full_df[\"count\"] = full_df[\"count\"].astype(int)\n",
    "\n",
    "    # Create a pivot table for each asset\n",
    "    pivot_tables = {\n",
    "        asset: full_df[full_df[\"asset\"] == asset].pivot(\n",
    "            index=\"component\", columns=\"state\", values=\"count\"\n",
    "        )\n",
    "        for asset in assets\n",
    "    }\n",
    "\n",
    "    # Sort the pivot_tables dictionary by asset keys\n",
    "    pivot_tables = {asset: pivot_tables[asset] for asset in sorted(pivot_tables)}\n",
    "\n",
    "    # Determine the global min and max for the counts, to use in color scale normalization\n",
    "    vmin = min(pivot.min().min() for pivot in pivot_tables.values())\n",
    "    vmax = max(pivot.max().max() for pivot in pivot_tables.values())\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(\n",
    "        1, len(assets), sharey=True, gridspec_kw={\"wspace\": 0.1}, figsize=(14, 8)\n",
    "    )\n",
    "\n",
    "    cmap = sns.color_palette(\"rocket_r\", as_cmap=True)\n",
    "    cmap.set_bad(\"whitesmoke\")\n",
    "\n",
    "\n",
    "    # Plot each pivot table in a subplot\n",
    "    for i, (asset, pivot_table) in enumerate(pivot_tables.items()):\n",
    "        ax = axes[i]\n",
    "        pivot_table = pivot_table.replace(0, np.nan)\n",
    "\n",
    "        sns.heatmap(\n",
    "            pivot_table,\n",
    "            ax=ax,\n",
    "            cbar=i == len(assets) - 1,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            cmap=cmap,\n",
    "            linewidth=4,\n",
    "            cbar_kws={\n",
    "                \"shrink\": 0.5,\n",
    "                \"label\": \"Count\" if i == len(assets) - 1 else \"\"\n",
    "                },\n",
    "        )\n",
    "\n",
    "        # Set title (asset name)\n",
    "        ax.set_title(\"Asset \" + asset, fontsize=12, pad=20)\n",
    "\n",
    "        # Configure y-axis (years)\n",
    "        ax.set_ylabel(\"Component\" if i == 0 else \"\", fontsize=12)  # Only show on first subplot\n",
    "        ax.yaxis.set_tick_params(labelsize=12, rotation=0)  # Horizontal year labels\n",
    "\n",
    "        # Configure x-axis (activities)\n",
    "        ax.set_xlabel(\"State\", fontsize=12)\n",
    "        ax.xaxis.set_tick_params(labelsize=12, rotation=90)  # Vertical activity labels\n",
    "\n",
    "        # If this is the last subplot (has colorbar)\n",
    "        if i == len(assets) - 1:\n",
    "            # Get the colorbar and adjust its properties\n",
    "            cbar = ax.collections[0].colorbar\n",
    "            cbar.ax.tick_params(labelsize=12)  # Set tick label size\n",
    "            cbar.ax.set_ylabel(\"Count\", fontsize=12)  # Set label size\n",
    "\n",
    "\n",
    "    # Save plot if path is provided\n",
    "    if save_path:\n",
    "        if not save_path.endswith('.pdf'):\n",
    "            save_path += '.pdf'\n",
    "        \n",
    "        plt.savefig(\n",
    "            save_path,\n",
    "            format='pdf',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=0.1\n",
    "        )\n",
    "        print(f\"Plot saved as: {save_path}\")\n",
    "\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_query_1_heatmap(query=query_1, save_path='./assets/query_1_heatmap_plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ2. What are the frequency and percentage distribution of failure states for component X on asset Y? (X = air conditioner, Y = hydraulic shovel)\n",
    "query_2 = '''\n",
    "MATCH (r:Record)-[:MENTIONS]->(n:`State/UndesirableState/FailedState`)-[rp:HAS_PATIENT]->(m)<-[:MENTIONS]-(r)\n",
    "WHERE id(rp) IN r.relationIds AND m.name = 'air conditioner'\n",
    "WITH r.floc AS system, m.name AS component, n.name AS state\n",
    "\n",
    "WITH system, component, state, COUNT(state) AS stateCount\n",
    "ORDER BY system, component, stateCount DESC\n",
    "WITH system, component, COLLECT(state) AS states, COLLECT(stateCount) AS stateCounts\n",
    "\n",
    "WITH system, component, states, stateCounts, REDUCE(s = 0, i IN stateCounts | s + i) AS totalStates\n",
    "\n",
    "UNWIND range(0, size(states)-1) AS idx\n",
    "WITH system, component, states[idx] AS state, stateCounts[idx] AS stateCount, totalStates,\n",
    "     (stateCounts[idx] * 100.0 / totalStates) AS percentage\n",
    "\n",
    "RETURN system, component, state, stateCount, percentage\n",
    "ORDER BY system, component, percentage\n",
    "'''\n",
    "\n",
    "# Note: The following query needs to be run in Neo4j Browser to get the subgraph.\n",
    "query_2_subgraph = '''\n",
    "MATCH p=(r:Record)-[:MENTIONS]->(n:`State/UndesirableState/FailedState`)-[rp:HAS_PATIENT]->(m)<-[:MENTIONS]-(r)\n",
    "WHERE id(rp) IN r.relationIds AND m.name = 'air conditioner'\n",
    "RETURN p\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_2_barchart(query: str, save_path: str = None):\n",
    "    \"\"\"\n",
    "    Creates a stacked bar chart showing the distribution of air conditioner states by system,\n",
    "    using an academic styling consistent with other visualizations.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Cypher query to fetch the data\n",
    "        save_path (str, optional): Path where to save the PDF file. \n",
    "                                 If None, plot will only be displayed.\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The generated plot\n",
    "    \"\"\"\n",
    "    # Data\n",
    "    data = {\n",
    "        'system': ['A', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'C', 'C', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'E', 'E'],\n",
    "        'component': ['air conditioner']*20,\n",
    "        'state': [\n",
    "            'no power', 'blowing hot air', 'no power', 'blowing hot', 'will not turn off', 'unserviceable', \n",
    "            'blowing hot air', 'not getting cold', 'not work', 'not work', 'not cool', 'unserviceable', \n",
    "            'not cool', 'blowing hot air', 'no power', 'blowing hot', 'not getting cold', 'not work', \n",
    "            'not work', 'not cool'\n",
    "        ],\n",
    "        'stateCount': [1, 3, 1, 1, 1, 2, 2, 2, 3, 1, 10, 1, 2, 3, 3, 3, 4, 12, 2, 7],\n",
    "        'percentage': [\n",
    "            25.0, 75.0, 8.33, 8.33, 8.33, 16.67, \n",
    "            16.67, 16.67, 25.0, 9.09, 90.91, 3.57, \n",
    "            7.14, 10.71, 10.71, 10.71, 14.29, \n",
    "            42.86, 22.22, 77.78\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Create DataFrame and pivot\n",
    "    df = pd.DataFrame(data)\n",
    "    df_pivot = df.pivot_table(\n",
    "        index='system',\n",
    "        columns='state',\n",
    "        values='percentage',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "    )\n",
    "\n",
    "    # Setup plot\n",
    "    plt.style.use('seaborn-v0_8-paper')\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    # Add grid lines\n",
    "    ax.grid(True, linestyle='--', alpha=0.3, color='gray', zorder=0)\n",
    "\n",
    "\n",
    "    # Define academic color palette\n",
    "    colors = [\n",
    "        '#4A6FA5',  # Steel blue\n",
    "        '#77A690',  # Sage green\n",
    "        '#9E857C',  # Warm gray\n",
    "        '#8B7355',  # Deep taupe\n",
    "        '#7B8B6F',  # Muted olive\n",
    "        '#6F7B8B',  # Slate blue\n",
    "        '#8B6F7B',  # Dusty rose\n",
    "        '#7B8B8B',  # Steel gray\n",
    "    ]\n",
    "\n",
    "    # Plot stacked bars and add labels\n",
    "    bottom = pd.Series([0]*len(df_pivot), index=df_pivot.index)\n",
    "    for i, column in enumerate(df_pivot.columns):\n",
    "        values = df_pivot[column]\n",
    "        bars = ax.bar(\n",
    "            df_pivot.index,\n",
    "            values,\n",
    "            bottom=bottom,\n",
    "            label=f\"{i+1}. {column}\",  # Add number to legend\n",
    "            color=colors[i],\n",
    "            edgecolor='black',\n",
    "            linewidth=0.5,\n",
    "            zorder=3\n",
    "        )\n",
    "        \n",
    "        # Add labels inside the bars\n",
    "        for j, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            if height > 5:  # Only show label if section is large enough (>5%)\n",
    "                x = bar.get_x() + bar.get_width()/2\n",
    "                y = bottom.iloc[j] + height/2  # Use iloc to access bottom values\n",
    "                ax.text(\n",
    "                    x, y,\n",
    "                    str(i+1),  # Show state number\n",
    "                    ha='center',\n",
    "                    va='center',\n",
    "                    color='white',\n",
    "                    fontweight='bold',\n",
    "                    fontsize=10\n",
    "                )\n",
    "        bottom += values\n",
    "    \n",
    "    # Customize plot appearance\n",
    "    ax.set_xlabel('Asset', fontsize=14)\n",
    "    ax.set_ylabel('Percentage (%)', fontsize=14)\n",
    "    ax.set_ylim(0, 100)\n",
    "    \n",
    "    # Set tick label font sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.xticks(rotation=0)\n",
    "    \n",
    "    # Adjust spine appearance\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(0.5)\n",
    "    ax.spines['bottom'].set_linewidth(0.5)\n",
    "    \n",
    "    # Add centered legend\n",
    "    box = ax.get_position()\n",
    "    # Shrink the width of the plot to make room for the legend\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.85, box.height])\n",
    "    \n",
    "    # Add legend on the right\n",
    "    legend = ax.legend(\n",
    "        title='State',\n",
    "        bbox_to_anchor=(1, 0.5),  # Position legend to the right\n",
    "        loc='center left',           # Anchor legend on the left side\n",
    "        fontsize=12,\n",
    "        frameon=True,\n",
    "        edgecolor='black',\n",
    "        fancybox=False,\n",
    "        ncol=1                       # Single column\n",
    "    )\n",
    "    legend.get_title().set_fontsize(12)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot if path is provided\n",
    "    if save_path:\n",
    "        if not save_path.endswith('.pdf'):\n",
    "            save_path += '.pdf'\n",
    "        \n",
    "        plt.savefig(\n",
    "            save_path,\n",
    "            format='pdf',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=0.1\n",
    "        )\n",
    "        print(f\"Plot saved as: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_query_2_barchart(query=query_2, save_path=r'D:\\Repos\\thesis\\thesis_ch08\\query_2_stacked_bar_plot.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Reliability Trends and Benchmarking of Equipment Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ3. What is the mean-time-to-failure (MTBF) for component X on the hydraulic shovels? (X = engine)\n",
    "query_3 = '''\n",
    "MATCH (r:Record)-[:MENTIONS]->(m:`State/UndesirableState/FailedState`)-[rp:HAS_PATIENT]-(n)<-[:MENTIONS]-(r)\n",
    "WHERE id(rp) IN r.relationIds AND n.name = 'engine'\n",
    "WITH r.floc AS system, m.name AS event, n.name AS component, r.text AS text, r.start_date AS start_date, r.cost AS cost\n",
    "WITH system, component, COUNT(*) AS count, collect(start_date) AS dates\n",
    "WITH system, component, count, dates, apoc.coll.sort(dates) AS sortedDates\n",
    "WITH system, component, count, sortedDates,\n",
    "     CASE WHEN size(sortedDates) > 1 THEN \n",
    "          reduce(s = 0, i IN range(1, size(sortedDates) - 1) | \n",
    "              s + duration.inDays(date(sortedDates[i - 1]), date(sortedDates[i])).days) / (size(sortedDates) - 1)\n",
    "     ELSE 0 END AS avgDaysBetweenEvents\n",
    "WHERE avgDaysBetweenEvents > 0\n",
    "RETURN system AS Asset, ABS(avgDaysBetweenEvents) AS MTBF, count As Events\n",
    "ORDER BY Asset\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_3_df = fetch_data(query=query_3)\n",
    "query_3_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Maintenance Costs and Budget Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total yearly maintenance and support costs for hydraulic shovels.\n",
    "query_4 = '''\n",
    "MATCH (r:Record)-[:MENTIONS]->(n)\n",
    "WHERE ANY(label IN labels(n) WHERE label STARTS WITH 'Activity/MaintenanceActivity/' OR label STARTS WITH 'Activity/SupportingActivity/')\n",
    "WITH r, n, r.start_date.year AS year, r.floc AS asset,\n",
    "     split(substring(replace(labels(n)[0], 'Activity', ''),1),'/')[0] AS activityType\n",
    "RETURN year, asset, activityType, COUNT(n) AS events, SUM(r.cost) AS totalCost\n",
    "ORDER BY year, asset\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_4_cluster_bar_plot(query: str, save_path: str = None):\n",
    "    \"\"\"\n",
    "    Creates a bar plot showing costs by year and asset, with side-by-side assets\n",
    "    and stacked maintenance/supporting activities.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Cypher query to fetch the data\n",
    "        save_path (str, optional): Path where to save the PDF file. \n",
    "                                 If None, plot will only be displayed.\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The generated plot\n",
    "    \"\"\"\n",
    "    # Fetch and preprocess data\n",
    "    df = fetch_data(query=query)\n",
    "    df = df[df['totalCost'] > 10000] # Remove rows where totalCost is 10,000\n",
    "    df['totalCost'] = df['totalCost'] / 1000000 # Convert totalCost to millions of dollar\n",
    "    # df = df[df['asset'] == 'D'] # Limit df to single asset\n",
    "\n",
    "    # Create pivot table for stacking\n",
    "    pivot_df = df.pivot_table(\n",
    "        index=['year', 'asset'],\n",
    "        columns='activityType',\n",
    "        values='totalCost',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "        ).reset_index()\n",
    "\n",
    "    # Setup plot with a white background\n",
    "    plt.style.use('seaborn-v0_8-paper')  # Use academic-style base\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Add grid lines\n",
    "    ax.grid(True, linestyle='--', alpha=0.3, color='gray', zorder=0)\n",
    "    \n",
    "    # Define plot parameters\n",
    "    years = sorted(pivot_df['year'].unique())\n",
    "    assets = sorted(pivot_df['asset'].unique())\n",
    "    n_years = len(years)\n",
    "    n_assets = len(assets)\n",
    "    \n",
    "    # Calculate bar positioning\n",
    "    bar_width = 0.8 / n_assets\n",
    "    year_positions = range(n_years)\n",
    "    \n",
    "    # Define academic color palette\n",
    "    # Using a combination of muted, professional colors suitable for publications\n",
    "    base_colors = [\n",
    "        '#4A6FA5',  # Steel blue\n",
    "        '#98A6B3',  # Slate gray\n",
    "        '#77A690',  # Sage green\n",
    "        '#9E857C',  # Warm gray\n",
    "        '#A69B7B',  # Taupe\n",
    "    ]\n",
    "    \n",
    "    # Create color map with lighter and darker versions for each asset\n",
    "    color_map = {}\n",
    "    for i, asset in enumerate(assets):\n",
    "        base_color = base_colors[i % len(base_colors)]\n",
    "        # Convert to RGB for manipulation\n",
    "        rgb_color = mcolors.to_rgb(base_color)\n",
    "        \n",
    "        # Create lighter version for Maintenance (20% lighter)\n",
    "        lighter_color = tuple(min(1.0, c * 1.2) for c in rgb_color)\n",
    "        # Create darker version for Supporting (30% darker)\n",
    "        darker_color = tuple(max(0.0, c * 0.7) for c in rgb_color)\n",
    "        \n",
    "        color_map[f'{asset}_Maintenance'] = lighter_color\n",
    "        color_map[f'{asset}_Supporting'] = darker_color\n",
    "    \n",
    "    # Plot bars for each asset\n",
    "    for asset_idx, asset in enumerate(assets):\n",
    "        # Calculate x positions for this asset's bars\n",
    "        x_positions = [x + (asset_idx - n_assets/2 + 0.5) * bar_width for x in year_positions]\n",
    "        \n",
    "        for year_idx, year in enumerate(years):\n",
    "            # Get data for this year and asset\n",
    "            mask = (pivot_df['year'] == year) & (pivot_df['asset'] == asset)\n",
    "            if any(mask):\n",
    "                maintenance_cost = pivot_df.loc[mask, 'Maintenance'].iloc[0]\n",
    "                supporting_cost = pivot_df.loc[mask, 'Supporting'].iloc[0]\n",
    "            else:\n",
    "                maintenance_cost = 0\n",
    "                supporting_cost = 0\n",
    "            \n",
    "            # Plot Maintenance (bottom bar)\n",
    "            ax.bar(x_positions[year_idx], maintenance_cost, \n",
    "                  bar_width, \n",
    "                  color=color_map[f'{asset}_Maintenance'],\n",
    "                  label=f'{asset} - Maintenance' if year_idx == 0 else \"\",\n",
    "                  zorder=3,\n",
    "                  edgecolor='black',     # Add black border\n",
    "                  linewidth=0.5)         # Thin border\n",
    "            \n",
    "            # Plot Supporting (top bar)\n",
    "            ax.bar(x_positions[year_idx], supporting_cost,\n",
    "                  bar_width,\n",
    "                  bottom=maintenance_cost,\n",
    "                  color=color_map[f'{asset}_Supporting'],\n",
    "                  label=f'{asset} - Supporting' if year_idx == 0 else \"\",\n",
    "                  zorder=3,\n",
    "                  edgecolor='black',     # Add black border\n",
    "                  linewidth=0.5)         # Thin border\n",
    "    \n",
    "    # Customize plot appearance\n",
    "    ax.set_xlabel('Year', fontsize=14)\n",
    "    ax.set_ylabel('Total Cost ($M)', fontsize=14)\n",
    "    ax.set_xticks(year_positions)\n",
    "    ax.set_xticklabels(years, rotation=45)\n",
    "    \n",
    "    # Set tick label font sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)  # Adjust the number 12 to your desired font size\n",
    "\n",
    "    # Adjust spine appearance\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(0.5)\n",
    "    ax.spines['bottom'].set_linewidth(0.5)\n",
    "    \n",
    "    # Add centered legend\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.85, box.height])\n",
    "    \n",
    "    # Add legend at the top center\n",
    "    legend = ax.legend(\n",
    "        title='Activity Type and Asset',\n",
    "        loc='upper center',\n",
    "        fontsize=12,\n",
    "        frameon=True,\n",
    "        edgecolor='black',\n",
    "        fancybox=False,\n",
    "        ncol=2  # Arrange legend items in two columns\n",
    "    )\n",
    "    legend.get_title().set_fontsize(12)  # Adjust legend title size\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot if path is provided\n",
    "    if save_path:\n",
    "        # Ensure the path ends with .pdf\n",
    "        if not save_path.endswith('.pdf'):\n",
    "            save_path += '.pdf'\n",
    "        \n",
    "        # Save with high DPI and tight layout\n",
    "        plt.savefig(\n",
    "            save_path,\n",
    "            format='pdf',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=0.1\n",
    "        )\n",
    "        print(f\"Plot saved as: {save_path}\")\n",
    "\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_query_4_cluster_bar_plot(query=query_4, save_path='./assets/query_4_cluster_bar_plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ5. How have the costs associated with X changed over the period N for asset Y? (X = 'Activity/MaintenanceActivity/Replace', N = 2006-2011, Y = hydraulic shovel)\n",
    "query_5 = '''\n",
    "MATCH (sys:System)--(r:Record)-[:MENTIONS]->(n:`Activity/MaintenanceActivity/Replace`)-[rp:HAS_PATIENT]-(o)-[:MENTIONS]-(r)\n",
    "WHERE id(rp) IN r.relationIds AND sys.name = 'D'\n",
    "WITH r, n, r.start_date.year AS year, o.name AS component\n",
    "WHERE year >= 2006 AND year <= 2011\n",
    "RETURN year, COUNT(n) AS eventCount, COLLECT(DISTINCT component) AS components, SUM(r.cost) AS totalCost\n",
    "ORDER BY year ASC\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_5_df = fetch_data(query=query_5)\n",
    "query_5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ6. What is the distribution of costs associated with maintenance activities performed on the hydraulic shovels?\n",
    "query_6 = '''\n",
    "MATCH (sys:System)--(r:Record)-[:MENTIONS]->(n)-[rp:HAS_PATIENT]-(o)-[:MENTIONS]-(r)\n",
    "WHERE labels(n)[0] CONTAINS 'Activity/MaintenanceActivity' AND id(rp) IN r.relationIds\n",
    "WITH r, n, sys, r.start_date.year AS year, o.name AS component\n",
    "RETURN year, sys.name AS asset, labels(n)[0] AS activity, COUNT(r) AS recordCount, SUM(r.cost) AS totalCost\n",
    "ORDER BY year ASC\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_6_heatmap(query: str, save_path: str=None):\n",
    "    df = fetch_data(query=query)\n",
    "    # Truncate activities to their last part\n",
    "    df['activity'] = df['activity'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "    # Get all unique activities and years to ensure all combinations are considered\n",
    "    activities = df[\"activity\"].unique()\n",
    "    years = df[\"year\"].unique()\n",
    "    # List of unique assets\n",
    "    assets = df[\"asset\"].unique()\n",
    "\n",
    "    # Create a DataFrame that includes all combinations for each asset\n",
    "    all_combinations = pd.DataFrame(\n",
    "        list(product(assets, activities, years)), columns=[\"asset\", \"activity\", \"year\"]\n",
    "    )\n",
    "\n",
    "    # Merge with original df to include counts\n",
    "    full_df = pd.merge(\n",
    "        all_combinations, df, on=[\"asset\", \"activity\", \"year\"], how=\"left\"\n",
    "    ).fillna(0)\n",
    "    full_df[\"totalCost\"] = full_df[\"totalCost\"].astype(float)\n",
    "\n",
    "    # Convert totalCost to millions\n",
    "    full_df[\"totalCost\"] = full_df[\"totalCost\"] / 1e6\n",
    "\n",
    "    # Create a pivot table for each asset\n",
    "    pivot_tables = {\n",
    "        asset: full_df[full_df[\"asset\"] == asset].pivot(\n",
    "            index=\"year\", columns=\"activity\", values=\"totalCost\"\n",
    "        )\n",
    "        for asset in assets\n",
    "    }\n",
    "\n",
    "    # Sort the pivot_tables dictionary by asset keys\n",
    "    pivot_tables = {asset: pivot_tables[asset] for asset in sorted(pivot_tables)}\n",
    "\n",
    "    # Determine the global min and max for the counts, to use in color scale normalization\n",
    "    vmin = min(pivot.min().min() for pivot in pivot_tables.values())\n",
    "    vmax = max(pivot.max().max() for pivot in pivot_tables.values())\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(\n",
    "        1, len(assets), sharey=True, gridspec_kw={\"wspace\": 0.1}, figsize=(14, 8)\n",
    "    )\n",
    "\n",
    "    cmap = sns.color_palette(\"rocket_r\", as_cmap=True)\n",
    "    cmap.set_bad(\"whitesmoke\")\n",
    "\n",
    "\n",
    "    # Plot each pivot table in a subplot\n",
    "    for i, (asset, pivot_table) in enumerate(pivot_tables.items()):\n",
    "        ax = axes[i]\n",
    "        pivot_table = pivot_table.replace(0, np.nan)\n",
    "        mask = pivot_table.isnull()\n",
    "        \n",
    "        # Create heatmap\n",
    "        sns.heatmap(\n",
    "            pivot_table,\n",
    "            ax=ax,\n",
    "            cbar=i == len(assets) - 1,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            cmap=cmap,\n",
    "            linewidth=4,\n",
    "            cbar_kws={\n",
    "                \"shrink\": 0.5, \n",
    "                \"label\": \"Total Cost ($M)\",\n",
    "                \"format\": \"%.1f\",\n",
    "                \"ticks\": plt.LinearLocator(6)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Set title (asset name)\n",
    "        ax.set_title(\"Asset \" + asset, fontsize=12, pad=20)\n",
    "        \n",
    "        # Configure y-axis (years)\n",
    "        ax.set_ylabel(\"Year\" if i == 0 else \"\", fontsize=12)  # Only show on first subplot\n",
    "        ax.yaxis.set_tick_params(labelsize=12, rotation=0)  # Horizontal year labels\n",
    "        \n",
    "        # Configure x-axis (activities)\n",
    "        ax.set_xlabel(\"Activity\", fontsize=12)\n",
    "        ax.xaxis.set_tick_params(labelsize=12, rotation=90)  # Vertical activity labels\n",
    "        \n",
    "        # If this is the last subplot (has colorbar)\n",
    "        if i == len(assets) - 1:\n",
    "            # Get the colorbar and adjust its properties\n",
    "            cbar = ax.collections[0].colorbar\n",
    "            cbar.ax.tick_params(labelsize=12)  # Set tick label size\n",
    "            cbar.ax.set_ylabel(\"Total Cost ($M)\", fontsize=12)  # Set label size\n",
    "\n",
    "    # Save plot if path is provided\n",
    "    if save_path:\n",
    "        if not save_path.endswith('.pdf'):\n",
    "            save_path += '.pdf'\n",
    "        \n",
    "        plt.savefig(\n",
    "            save_path,\n",
    "            format='pdf',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=0.1\n",
    "        )\n",
    "        print(f\"Plot saved as: {save_path}\")\n",
    "\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_query_6_heatmap(query=query_6, save_path='./assets/query_6_heatmap_plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ7. What are the cost implications of components participating in different states or processes?\n",
    "query_7 = '''\n",
    "MATCH p=(r:Record)-[:MENTIONS]->(m)-[ra:HAS_AGENT]-(n)<-[:MENTIONS]-(r)-[:MENTIONS]->(q)<-[rp:HAS_PATIENT]-(m)\n",
    "WHERE m.name CONTAINS 'leak' AND id(rp) IN r.relationIds AND id(ra) IN r.relationIds \n",
    "WITH r.floc AS system, m.name AS event, q.name AS substance, n.name AS component, COUNT(*) AS count, SUM(r.cost) AS totalCost\n",
    "WHERE totalCost > 5000\n",
    "RETURN system, component, event, substance, count, totalCost\n",
    "ORDER BY system, totalCost DESC\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_7_df = fetch_data(query=query_7)\n",
    "query_7_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Discovery and Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ8. Provide a taxonomical breakdown of X. (X = engine)\n",
    "# Note: the return statement of this query has been modified to allow it be represented as a table. Replace it with `RETURN p` and execute within Neo4J to see the sugraph network.\n",
    "query_8 = '''\n",
    "MATCH p=(n)-[r:HAS_PART]->(m)\n",
    "WHERE labels(n)[0] CONTAINS 'Object' AND labels(m)[0] CONTAINS 'Object' AND n.name = 'engine' AND r.frequency > 1\n",
    "RETURN n.name AS component, m.name AS part, r.frequency AS count\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_8_df = fetch_data(query=query_8)\n",
    "# Show the top 25 rows\n",
    "query_8_df.head(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
