{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaintKG Case Study: Using Neo4J Cypher Queries to Address Expert Competency Query\n",
    "![Maintenance](https://img.shields.io/badge/Maintenance-Analysis-blue)\n",
    "![Python](https://img.shields.io/badge/Python-3.9-green)\n",
    "![Neo4j](https://img.shields.io/badge/Neo4j-4.4+-orange)\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates example queries that map to expert competency questions for the MaintKG case study. Through these queries, we explore maintenance patterns, component relationships, and failure analysis within the knowledge graph.\n",
    "\n",
    "### Environment Setup\n",
    "- Python virtual environment activated (`venv`)\n",
    "- Required packages installed (see `requirements.txt`)\n",
    "- Python 3.9 or later\n",
    "\n",
    "### Database Requirements\n",
    "- Neo4j database instance running (version 4.4+)\n",
    "- MaintKG populated with case study data\n",
    "- Valid database credentials configured\n",
    "\n",
    "### Output Information\n",
    "- Plots are automatically saved to `./assets` in PDF format\n",
    "- Query results can be exported to CSV files\n",
    "- Visualizations use matplotlib and seaborn libraries\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "1. [Notebook Setup](#notebook-setup)\n",
    "2. [Cypher Queries](#cypher-queries)\n",
    "    1. [Identification of Failures and Defects](#identification-of-failures-and-defects)\n",
    "    2. [Analysis of Reliability Trends](#analysis-of-reliability-trends-and-benchmarking-of-equipment-performance)\n",
    "    3. [Analysis of Maintenance Costs](#analysis-of-maintenance-costs-and-budget-allocation)\n",
    "    4. [Knowledge Discovery and Management](#knowledge-discovery-and-management)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "from neo4j import GraphDatabase\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from maintkg.settings import Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the Neo4J connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Settings()\n",
    "\n",
    "driver = GraphDatabase.driver(settings.neo4j.uri, auth=(settings.neo4j.username, settings.neo4j.password), database=settings.neo4j.database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(query: str) -> pd.DataFrame:\n",
    "    \"\"\"Fetch data from Neo4j and return a DataFrame.\"\"\"\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        data = result.data()    # Fetch all results    \n",
    "        df = pd.DataFrame(data) # Convert the list of dictionaries to a DataFrame\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cypher Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identification of Failures and Defects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ1. What is the top-n distribution of undesirable states for components on all hydraulic shovels?\n",
    "query_1 = '''\n",
    "MATCH p=(r:Record)-[:MENTIONS]->(n)-[rp:HAS_PATIENT]->(m)-[:MENTIONS]-(r)\n",
    "WHERE id(rp) IN r.relationIds AND labels(n)[0] CONTAINS 'State' AND labels(m)[0] CONTAINS 'Object'\n",
    "WITH r.floc AS asset, n.name AS state, m.name AS component, COUNT(p) AS count\n",
    "WHERE count > 10\n",
    "RETURN asset, state, component, count\n",
    "ORDER BY state, component\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_1_heatmap(query: str, save_path: str = None) -> None:\n",
    "    ''''''\n",
    "    df = fetch_data(query=query)\n",
    "    # Get all unique components and states to ensure all combinations are considered\n",
    "    components = df[\"component\"].unique()\n",
    "    states = df[\"state\"].unique()\n",
    "\n",
    "    # List of unique assets\n",
    "    assets = df[\"asset\"].unique()\n",
    "\n",
    "    # Create a DataFrame that includes all combinations for each asset\n",
    "    all_combinations = pd.DataFrame(\n",
    "        list(product(assets, components, states)), columns=[\"asset\", \"component\", \"state\"]\n",
    "    )\n",
    "\n",
    "    # Merge with original df to include counts\n",
    "    full_df = pd.merge(\n",
    "        all_combinations, df, on=[\"asset\", \"component\", \"state\"], how=\"left\"\n",
    "    ).fillna(0)\n",
    "\n",
    "    full_df[\"count\"] = full_df[\"count\"].astype(int)\n",
    "\n",
    "    # Create a pivot table for each asset\n",
    "    pivot_tables = {\n",
    "        asset: full_df[full_df[\"asset\"] == asset].pivot(\n",
    "            index=\"component\", columns=\"state\", values=\"count\"\n",
    "        )\n",
    "        for asset in assets\n",
    "    }\n",
    "\n",
    "    # Sort the pivot_tables dictionary by asset keys\n",
    "    pivot_tables = {asset: pivot_tables[asset] for asset in sorted(pivot_tables)}\n",
    "\n",
    "    # Determine the global min and max for the counts, to use in color scale normalization\n",
    "    vmin = min(pivot.min().min() for pivot in pivot_tables.values())\n",
    "    vmax = max(pivot.max().max() for pivot in pivot_tables.values())\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(\n",
    "        1, len(assets), sharey=True, gridspec_kw={\"wspace\": 0.1}, figsize=(14, 8)\n",
    "    )\n",
    "\n",
    "    cmap = sns.color_palette(\"rocket_r\", as_cmap=True)\n",
    "    cmap.set_bad(\"whitesmoke\")\n",
    "\n",
    "\n",
    "    # Plot each pivot table in a subplot\n",
    "    for i, (asset, pivot_table) in enumerate(pivot_tables.items()):\n",
    "        ax = axes[i]\n",
    "        pivot_table = pivot_table.replace(0, np.nan)\n",
    "\n",
    "        sns.heatmap(\n",
    "            pivot_table,\n",
    "            ax=ax,\n",
    "            cbar=i == len(assets) - 1,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            cmap=cmap,\n",
    "            linewidth=4,\n",
    "            cbar_kws={\n",
    "                \"shrink\": 0.5,\n",
    "                \"label\": \"Count\" if i == len(assets) - 1 else \"\"\n",
    "                },\n",
    "        )\n",
    "\n",
    "        # Set title (asset name)\n",
    "        ax.set_title(\"Asset \" + asset, fontsize=12, pad=20)\n",
    "\n",
    "        # Configure y-axis (years)\n",
    "        ax.set_ylabel(\"Component\" if i == 0 else \"\", fontsize=12)  # Only show on first subplot\n",
    "        ax.yaxis.set_tick_params(labelsize=12, rotation=0)  # Horizontal year labels\n",
    "\n",
    "        # Configure x-axis (activities)\n",
    "        ax.set_xlabel(\"State\", fontsize=12)\n",
    "        ax.xaxis.set_tick_params(labelsize=12, rotation=90)  # Vertical activity labels\n",
    "\n",
    "        # If this is the last subplot (has colorbar)\n",
    "        if i == len(assets) - 1:\n",
    "            # Get the colorbar and adjust its properties\n",
    "            cbar = ax.collections[0].colorbar\n",
    "            cbar.ax.tick_params(labelsize=12)  # Set tick label size\n",
    "            cbar.ax.set_ylabel(\"Count\", fontsize=12)  # Set label size\n",
    "\n",
    "\n",
    "    # Save plot if path is provided\n",
    "    if save_path:\n",
    "        if not save_path.endswith('.pdf'):\n",
    "            save_path += '.pdf'\n",
    "        \n",
    "        plt.savefig(\n",
    "            save_path,\n",
    "            format='pdf',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=0.1\n",
    "        )\n",
    "        print(f\"Plot saved as: {save_path}\")\n",
    "\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthError",
     "evalue": "{code: Neo.ClientError.Security.Unauthorized} {message: The client is unauthorized due to authentication failure.}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcreate_query_1_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./assets/query_1_heatmap_plot.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m, in \u001b[0;36mcreate_query_1_heatmap\u001b[1;34m(query, save_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_query_1_heatmap\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m, save_path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''''''\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Get all unique components and states to ensure all combinations are considered\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     components \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m, in \u001b[0;36mfetch_data\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fetch data from Neo4j and return a DataFrame.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m driver\u001b[38;5;241m.\u001b[39msession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m----> 4\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     data \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mdata()    \u001b[38;5;66;03m# Fetch all results    \u001b[39;00m\n\u001b[0;32m      6\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data) \u001b[38;5;66;03m# Convert the list of dictionaries to a DataFrame\u001b[39;00m\n",
      "File \u001b[1;32md:\\Repos\\thesis\\MaintKG\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py:306\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_result\u001b[38;5;241m.\u001b[39m_buffer_all()\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection:\n\u001b[1;32m--> 306\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_access_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    308\u001b[0m cx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\n",
      "File \u001b[1;32md:\\Repos\\thesis\\MaintKG\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py:130\u001b[0m, in \u001b[0;36mSession._connect\u001b[1;34m(self, access_mode, **acquire_kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     access_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdefault_access_mode\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_connect(\n\u001b[0;32m    131\u001b[0m         access_mode, auth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mauth, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39macquire_kwargs\n\u001b[0;32m    132\u001b[0m     )\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_cancellation(message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_connect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Repos\\thesis\\MaintKG\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py:184\u001b[0m, in \u001b[0;36mWorkspace._connect\u001b[1;34m(self, access_mode, auth, **acquire_kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m acquire_kwargs_ \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccess_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: access_mode,\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: acquisition_timeout,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliveness_check_timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    182\u001b[0m }\n\u001b[0;32m    183\u001b[0m acquire_kwargs_\u001b[38;5;241m.\u001b[39mupdate(acquire_kwargs)\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39macquire_kwargs_)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_access_mode \u001b[38;5;241m=\u001b[39m access_mode\n",
      "File \u001b[1;32md:\\Repos\\thesis\\MaintKG\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:596\u001b[0m, in \u001b[0;36mBoltPool.acquire\u001b[1;34m(self, access_mode, timeout, database, bookmarks, auth, liveness_check_timeout)\u001b[0m\n\u001b[0;32m    589\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  _: <POOL> acquire direct connection, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccess_mode=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m, database=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    592\u001b[0m     access_mode,\n\u001b[0;32m    593\u001b[0m     database,\n\u001b[0;32m    594\u001b[0m )\n\u001b[0;32m    595\u001b[0m deadline \u001b[38;5;241m=\u001b[39m Deadline\u001b[38;5;241m.\u001b[39mfrom_timeout_or_deadline(timeout)\n\u001b[1;32m--> 596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mliveness_check_timeout\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Repos\\thesis\\MaintKG\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:346\u001b[0m, in \u001b[0;36mIOPool._acquire\u001b[1;34m(self, address, auth, deadline, liveness_check_timeout)\u001b[0m\n\u001b[0;32m    341\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ClientError(\n\u001b[0;32m    342\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed to obtain a connection from the pool within \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    343\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeadline\u001b[38;5;241m.\u001b[39moriginal_timeout\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124ms (timeout)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m             )\n\u001b[0;32m    345\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  _: <POOL> trying to hand out new connection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Repos\\thesis\\MaintKG\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:169\u001b[0m, in \u001b[0;36mIOPool._acquire_new_later.<locals>.connection_creator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m         connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopener\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeadline\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ServiceUnavailable:\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeactivate(address)\n",
      "File \u001b[1;32md:\\Repos\\thesis\\MaintKG\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:559\u001b[0m, in \u001b[0;36mBoltPool.open.<locals>.opener\u001b[1;34m(addr, auth_manager, deadline)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopener\u001b[39m(addr, auth_manager, deadline):\n\u001b[1;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBolt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrouting_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Repos\\thesis\\MaintKG\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:553\u001b[0m, in \u001b[0;36mBolt.open\u001b[1;34m(cls, address, auth_manager, deadline, routing_context, pool_config)\u001b[0m\n\u001b[0;32m    551\u001b[0m connection\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mset_deadline(deadline)\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 553\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhello\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    555\u001b[0m     connection\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mset_deadline(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Repos\\thesis\\MaintKG\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt5.py:174\u001b[0m, in \u001b[0;36mBolt5x0.hello\u001b[1;34m(self, dehydration_hooks, hydration_hooks)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append(\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    167\u001b[0m     (headers,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m     dehydration_hooks\u001b[38;5;241m=\u001b[39mdehydration_hooks,\n\u001b[0;32m    172\u001b[0m )\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_all()\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m check_supported_server_product(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_info\u001b[38;5;241m.\u001b[39magent)\n",
      "File \u001b[1;32md:\\Repos\\thesis\\MaintKG\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:992\u001b[0m, in \u001b[0;36mBolt.fetch_all\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    990\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcomplete:\n\u001b[1;32m--> 992\u001b[0m     detail_delta, summary_delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    993\u001b[0m     detail_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m detail_delta\n\u001b[0;32m    994\u001b[0m     summary_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m summary_delta\n",
      "File \u001b[1;32md:\\Repos\\thesis\\MaintKG\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:977\u001b[0m, in \u001b[0;36mBolt.fetch_message\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[0;32m    974\u001b[0m tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minbox\u001b[38;5;241m.\u001b[39mpop(\n\u001b[0;32m    975\u001b[0m     hydration_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhydration_hooks\n\u001b[0;32m    976\u001b[0m )\n\u001b[1;32m--> 977\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midle_since \u001b[38;5;241m=\u001b[39m monotonic()\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32md:\\Repos\\thesis\\MaintKG\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt5.py:466\u001b[0m, in \u001b[0;36mBolt5x0._process_message\u001b[1;34m(self, tag, fields)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_state_manager\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbolt_states\u001b[38;5;241m.\u001b[39mFAILED\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 466\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool:\n",
      "File \u001b[1;32md:\\Repos\\thesis\\MaintKG\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_common.py:274\u001b[0m, in \u001b[0;36mInitResponse.on_failure\u001b[1;34m(self, metadata)\u001b[0m\n\u001b[0;32m    269\u001b[0m Util\u001b[38;5;241m.\u001b[39mcallback(handler)\n\u001b[0;32m    270\u001b[0m metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection initialisation failed due to an unknown error\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    273\u001b[0m )\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Neo4jError\u001b[38;5;241m.\u001b[39mhydrate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata)\n",
      "\u001b[1;31mAuthError\u001b[0m: {code: Neo.ClientError.Security.Unauthorized} {message: The client is unauthorized due to authentication failure.}"
     ]
    }
   ],
   "source": [
    "create_query_1_heatmap(query=query_1, save_path='./assets/query_1_heatmap_plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ2. What are the frequency and percentage distribution of failure states for component X on asset Y? (X = air conditioner, Y = hydraulic shovel)\n",
    "query_2 = '''\n",
    "MATCH (r:Record)-[:MENTIONS]->(n:`State/UndesirableState/FailedState`)-[rp:HAS_PATIENT]->(m)<-[:MENTIONS]-(r)\n",
    "WHERE id(rp) IN r.relationIds AND m.name = 'air conditioner'\n",
    "WITH r.floc AS system, m.name AS component, n.name AS state\n",
    "\n",
    "WITH system, component, state, COUNT(state) AS stateCount\n",
    "ORDER BY system, component, stateCount DESC\n",
    "WITH system, component, COLLECT(state) AS states, COLLECT(stateCount) AS stateCounts\n",
    "\n",
    "WITH system, component, states, stateCounts, REDUCE(s = 0, i IN stateCounts | s + i) AS totalStates\n",
    "\n",
    "UNWIND range(0, size(states)-1) AS idx\n",
    "WITH system, component, states[idx] AS state, stateCounts[idx] AS stateCount, totalStates,\n",
    "     (stateCounts[idx] * 100.0 / totalStates) AS percentage\n",
    "\n",
    "RETURN system, component, state, stateCount, percentage\n",
    "ORDER BY system, component, percentage\n",
    "'''\n",
    "\n",
    "# Note: The following query needs to be run in Neo4j Browser to get the subgraph.\n",
    "query_2_subgraph = '''\n",
    "MATCH p=(r:Record)-[:MENTIONS]->(n:`State/UndesirableState/FailedState`)-[rp:HAS_PATIENT]->(m)<-[:MENTIONS]-(r)\n",
    "WHERE id(rp) IN r.relationIds AND m.name = 'air conditioner'\n",
    "RETURN p\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_2_barchart(query: str, save_path: str = None):\n",
    "    \"\"\"\n",
    "    Creates a stacked bar chart showing the distribution of air conditioner states by system,\n",
    "    using an academic styling consistent with other visualizations.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Cypher query to fetch the data\n",
    "        save_path (str, optional): Path where to save the PDF file. \n",
    "                                 If None, plot will only be displayed.\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The generated plot\n",
    "    \"\"\"\n",
    "    # Data\n",
    "    data = {\n",
    "        'system': ['A', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'C', 'C', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'E', 'E'],\n",
    "        'component': ['air conditioner']*20,\n",
    "        'state': [\n",
    "            'no power', 'blowing hot air', 'no power', 'blowing hot', 'will not turn off', 'unserviceable', \n",
    "            'blowing hot air', 'not getting cold', 'not work', 'not work', 'not cool', 'unserviceable', \n",
    "            'not cool', 'blowing hot air', 'no power', 'blowing hot', 'not getting cold', 'not work', \n",
    "            'not work', 'not cool'\n",
    "        ],\n",
    "        'stateCount': [1, 3, 1, 1, 1, 2, 2, 2, 3, 1, 10, 1, 2, 3, 3, 3, 4, 12, 2, 7],\n",
    "        'percentage': [\n",
    "            25.0, 75.0, 8.33, 8.33, 8.33, 16.67, \n",
    "            16.67, 16.67, 25.0, 9.09, 90.91, 3.57, \n",
    "            7.14, 10.71, 10.71, 10.71, 14.29, \n",
    "            42.86, 22.22, 77.78\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Create DataFrame and pivot\n",
    "    df = pd.DataFrame(data)\n",
    "    df_pivot = df.pivot_table(\n",
    "        index='system',\n",
    "        columns='state',\n",
    "        values='percentage',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "    )\n",
    "\n",
    "    # Setup plot\n",
    "    plt.style.use('seaborn-v0_8-paper')\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    # Add grid lines\n",
    "    ax.grid(True, linestyle='--', alpha=0.3, color='gray', zorder=0)\n",
    "\n",
    "\n",
    "    # Define academic color palette\n",
    "    colors = [\n",
    "        '#4A6FA5',  # Steel blue\n",
    "        '#77A690',  # Sage green\n",
    "        '#9E857C',  # Warm gray\n",
    "        '#8B7355',  # Deep taupe\n",
    "        '#7B8B6F',  # Muted olive\n",
    "        '#6F7B8B',  # Slate blue\n",
    "        '#8B6F7B',  # Dusty rose\n",
    "        '#7B8B8B',  # Steel gray\n",
    "    ]\n",
    "\n",
    "    # Plot stacked bars and add labels\n",
    "    bottom = pd.Series([0]*len(df_pivot), index=df_pivot.index)\n",
    "    for i, column in enumerate(df_pivot.columns):\n",
    "        values = df_pivot[column]\n",
    "        bars = ax.bar(\n",
    "            df_pivot.index,\n",
    "            values,\n",
    "            bottom=bottom,\n",
    "            label=f\"{i+1}. {column}\",  # Add number to legend\n",
    "            color=colors[i],\n",
    "            edgecolor='black',\n",
    "            linewidth=0.5,\n",
    "            zorder=3\n",
    "        )\n",
    "        \n",
    "        # Add labels inside the bars\n",
    "        for j, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            if height > 5:  # Only show label if section is large enough (>5%)\n",
    "                x = bar.get_x() + bar.get_width()/2\n",
    "                y = bottom.iloc[j] + height/2  # Use iloc to access bottom values\n",
    "                ax.text(\n",
    "                    x, y,\n",
    "                    str(i+1),  # Show state number\n",
    "                    ha='center',\n",
    "                    va='center',\n",
    "                    color='white',\n",
    "                    fontweight='bold',\n",
    "                    fontsize=10\n",
    "                )\n",
    "        bottom += values\n",
    "    \n",
    "    # Customize plot appearance\n",
    "    ax.set_xlabel('Asset', fontsize=14)\n",
    "    ax.set_ylabel('Percentage (%)', fontsize=14)\n",
    "    ax.set_ylim(0, 100)\n",
    "    \n",
    "    # Set tick label font sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.xticks(rotation=0)\n",
    "    \n",
    "    # Adjust spine appearance\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(0.5)\n",
    "    ax.spines['bottom'].set_linewidth(0.5)\n",
    "    \n",
    "    # Add centered legend\n",
    "    box = ax.get_position()\n",
    "    # Shrink the width of the plot to make room for the legend\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.85, box.height])\n",
    "    \n",
    "    # Add legend on the right\n",
    "    legend = ax.legend(\n",
    "        title='State',\n",
    "        bbox_to_anchor=(1, 0.5),  # Position legend to the right\n",
    "        loc='center left',           # Anchor legend on the left side\n",
    "        fontsize=12,\n",
    "        frameon=True,\n",
    "        edgecolor='black',\n",
    "        fancybox=False,\n",
    "        ncol=1                       # Single column\n",
    "    )\n",
    "    legend.get_title().set_fontsize(12)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot if path is provided\n",
    "    if save_path:\n",
    "        if not save_path.endswith('.pdf'):\n",
    "            save_path += '.pdf'\n",
    "        \n",
    "        plt.savefig(\n",
    "            save_path,\n",
    "            format='pdf',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=0.1\n",
    "        )\n",
    "        print(f\"Plot saved as: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_query_2_barchart(query=query_2, save_path='./assets/query_2_stacked_bar_plot.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Reliability Trends and Benchmarking of Equipment Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ3. What is the mean-time-to-failure (MTBF) for component X on the hydraulic shovels? (X = engine)\n",
    "query_3 = '''\n",
    "MATCH (r:Record)-[:MENTIONS]->(m:`State/UndesirableState/FailedState`)-[rp:HAS_PATIENT]-(n)<-[:MENTIONS]-(r)\n",
    "WHERE id(rp) IN r.relationIds AND n.name = 'engine'\n",
    "WITH r.floc AS system, m.name AS event, n.name AS component, r.text AS text, r.start_date AS start_date, r.cost AS cost\n",
    "WITH system, component, COUNT(*) AS count, collect(start_date) AS dates\n",
    "WITH system, component, count, dates, apoc.coll.sort(dates) AS sortedDates\n",
    "WITH system, component, count, sortedDates,\n",
    "     CASE WHEN size(sortedDates) > 1 THEN \n",
    "          reduce(s = 0, i IN range(1, size(sortedDates) - 1) | \n",
    "              s + duration.inDays(date(sortedDates[i - 1]), date(sortedDates[i])).days) / (size(sortedDates) - 1)\n",
    "     ELSE 0 END AS avgDaysBetweenEvents\n",
    "WHERE avgDaysBetweenEvents > 0\n",
    "RETURN system AS Asset, ABS(avgDaysBetweenEvents) AS MTBF, count As Events\n",
    "ORDER BY Asset\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_3_df = fetch_data(query=query_3)\n",
    "query_3_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Maintenance Costs and Budget Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total yearly maintenance and support costs for hydraulic shovels.\n",
    "query_4 = '''\n",
    "MATCH (r:Record)-[:MENTIONS]->(n)\n",
    "WHERE ANY(label IN labels(n) WHERE label STARTS WITH 'Activity/MaintenanceActivity/' OR label STARTS WITH 'Activity/SupportingActivity/')\n",
    "WITH r, n, r.start_date.year AS year, r.floc AS asset,\n",
    "     split(substring(replace(labels(n)[0], 'Activity', ''),1),'/')[0] AS activityType\n",
    "RETURN year, asset, activityType, COUNT(n) AS events, SUM(r.cost) AS totalCost\n",
    "ORDER BY year, asset\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_4_cluster_bar_plot(query: str, save_path: str = None):\n",
    "    \"\"\"\n",
    "    Creates a bar plot showing costs by year and asset, with side-by-side assets\n",
    "    and stacked maintenance/supporting activities.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Cypher query to fetch the data\n",
    "        save_path (str, optional): Path where to save the PDF file. \n",
    "                                 If None, plot will only be displayed.\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The generated plot\n",
    "    \"\"\"\n",
    "    # Fetch and preprocess data\n",
    "    df = fetch_data(query=query)\n",
    "    df = df[df['totalCost'] > 10000] # Remove rows where totalCost is 10,000\n",
    "    df['totalCost'] = df['totalCost'] / 1000000 # Convert totalCost to millions of dollar\n",
    "    # df = df[df['asset'] == 'D'] # Limit df to single asset\n",
    "\n",
    "    # Create pivot table for stacking\n",
    "    pivot_df = df.pivot_table(\n",
    "        index=['year', 'asset'],\n",
    "        columns='activityType',\n",
    "        values='totalCost',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "        ).reset_index()\n",
    "\n",
    "    # Setup plot with a white background\n",
    "    plt.style.use('seaborn-v0_8-paper')  # Use academic-style base\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Add grid lines\n",
    "    ax.grid(True, linestyle='--', alpha=0.3, color='gray', zorder=0)\n",
    "    \n",
    "    # Define plot parameters\n",
    "    years = sorted(pivot_df['year'].unique())\n",
    "    assets = sorted(pivot_df['asset'].unique())\n",
    "    n_years = len(years)\n",
    "    n_assets = len(assets)\n",
    "    \n",
    "    # Calculate bar positioning\n",
    "    bar_width = 0.8 / n_assets\n",
    "    year_positions = range(n_years)\n",
    "    \n",
    "    # Define academic color palette\n",
    "    # Using a combination of muted, professional colors suitable for publications\n",
    "    base_colors = [\n",
    "        '#4A6FA5',  # Steel blue\n",
    "        '#98A6B3',  # Slate gray\n",
    "        '#77A690',  # Sage green\n",
    "        '#9E857C',  # Warm gray\n",
    "        '#A69B7B',  # Taupe\n",
    "    ]\n",
    "    \n",
    "    # Create color map with lighter and darker versions for each asset\n",
    "    color_map = {}\n",
    "    for i, asset in enumerate(assets):\n",
    "        base_color = base_colors[i % len(base_colors)]\n",
    "        # Convert to RGB for manipulation\n",
    "        rgb_color = mcolors.to_rgb(base_color)\n",
    "        \n",
    "        # Create lighter version for Maintenance (20% lighter)\n",
    "        lighter_color = tuple(min(1.0, c * 1.2) for c in rgb_color)\n",
    "        # Create darker version for Supporting (30% darker)\n",
    "        darker_color = tuple(max(0.0, c * 0.7) for c in rgb_color)\n",
    "        \n",
    "        color_map[f'{asset}_Maintenance'] = lighter_color\n",
    "        color_map[f'{asset}_Supporting'] = darker_color\n",
    "    \n",
    "    # Plot bars for each asset\n",
    "    for asset_idx, asset in enumerate(assets):\n",
    "        # Calculate x positions for this asset's bars\n",
    "        x_positions = [x + (asset_idx - n_assets/2 + 0.5) * bar_width for x in year_positions]\n",
    "        \n",
    "        for year_idx, year in enumerate(years):\n",
    "            # Get data for this year and asset\n",
    "            mask = (pivot_df['year'] == year) & (pivot_df['asset'] == asset)\n",
    "            if any(mask):\n",
    "                maintenance_cost = pivot_df.loc[mask, 'Maintenance'].iloc[0]\n",
    "                supporting_cost = pivot_df.loc[mask, 'Supporting'].iloc[0]\n",
    "            else:\n",
    "                maintenance_cost = 0\n",
    "                supporting_cost = 0\n",
    "            \n",
    "            # Plot Maintenance (bottom bar)\n",
    "            ax.bar(x_positions[year_idx], maintenance_cost, \n",
    "                  bar_width, \n",
    "                  color=color_map[f'{asset}_Maintenance'],\n",
    "                  label=f'{asset} - Maintenance' if year_idx == 0 else \"\",\n",
    "                  zorder=3,\n",
    "                  edgecolor='black',     # Add black border\n",
    "                  linewidth=0.5)         # Thin border\n",
    "            \n",
    "            # Plot Supporting (top bar)\n",
    "            ax.bar(x_positions[year_idx], supporting_cost,\n",
    "                  bar_width,\n",
    "                  bottom=maintenance_cost,\n",
    "                  color=color_map[f'{asset}_Supporting'],\n",
    "                  label=f'{asset} - Supporting' if year_idx == 0 else \"\",\n",
    "                  zorder=3,\n",
    "                  edgecolor='black',     # Add black border\n",
    "                  linewidth=0.5)         # Thin border\n",
    "    \n",
    "    # Customize plot appearance\n",
    "    ax.set_xlabel('Year', fontsize=14)\n",
    "    ax.set_ylabel('Total Cost ($M)', fontsize=14)\n",
    "    ax.set_xticks(year_positions)\n",
    "    ax.set_xticklabels(years, rotation=45)\n",
    "    \n",
    "    # Set tick label font sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)  # Adjust the number 12 to your desired font size\n",
    "\n",
    "    # Adjust spine appearance\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(0.5)\n",
    "    ax.spines['bottom'].set_linewidth(0.5)\n",
    "    \n",
    "    # Add centered legend\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.85, box.height])\n",
    "    \n",
    "    # Add legend at the top center\n",
    "    legend = ax.legend(\n",
    "        title='Activity Type and Asset',\n",
    "        loc='upper center',\n",
    "        fontsize=12,\n",
    "        frameon=True,\n",
    "        edgecolor='black',\n",
    "        fancybox=False,\n",
    "        ncol=2  # Arrange legend items in two columns\n",
    "    )\n",
    "    legend.get_title().set_fontsize(12)  # Adjust legend title size\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot if path is provided\n",
    "    if save_path:\n",
    "        # Ensure the path ends with .pdf\n",
    "        if not save_path.endswith('.pdf'):\n",
    "            save_path += '.pdf'\n",
    "        \n",
    "        # Save with high DPI and tight layout\n",
    "        plt.savefig(\n",
    "            save_path,\n",
    "            format='pdf',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=0.1\n",
    "        )\n",
    "        print(f\"Plot saved as: {save_path}\")\n",
    "\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_query_4_cluster_bar_plot(query=query_4, save_path='./assets/query_4_cluster_bar_plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ5. How have the costs associated with X changed over the period N for asset Y? (X = 'Activity/MaintenanceActivity/Replace', N = 2006-2011, Y = hydraulic shovel)\n",
    "query_5 = '''\n",
    "MATCH (sys:System)--(r:Record)-[:MENTIONS]->(n:`Activity/MaintenanceActivity/Replace`)-[rp:HAS_PATIENT]-(o)-[:MENTIONS]-(r)\n",
    "WHERE id(rp) IN r.relationIds AND sys.name = 'D'\n",
    "WITH r, n, r.start_date.year AS year, o.name AS component\n",
    "WHERE year >= 2006 AND year <= 2011\n",
    "RETURN year, COUNT(n) AS eventCount, COLLECT(DISTINCT component) AS components, SUM(r.cost) AS totalCost\n",
    "ORDER BY year ASC\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_5_df = fetch_data(query=query_5)\n",
    "query_5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ6. What is the distribution of costs associated with maintenance activities performed on the hydraulic shovels?\n",
    "query_6 = '''\n",
    "MATCH (sys:System)--(r:Record)-[:MENTIONS]->(n)-[rp:HAS_PATIENT]-(o)-[:MENTIONS]-(r)\n",
    "WHERE labels(n)[0] CONTAINS 'Activity/MaintenanceActivity' AND id(rp) IN r.relationIds\n",
    "WITH r, n, sys, r.start_date.year AS year, o.name AS component\n",
    "RETURN year, sys.name AS asset, labels(n)[0] AS activity, COUNT(r) AS recordCount, SUM(r.cost) AS totalCost\n",
    "ORDER BY year ASC\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_6_heatmap(query: str, save_path: str=None):\n",
    "    df = fetch_data(query=query)\n",
    "    # Truncate activities to their last part\n",
    "    df['activity'] = df['activity'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "    # Get all unique activities and years to ensure all combinations are considered\n",
    "    activities = df[\"activity\"].unique()\n",
    "    years = df[\"year\"].unique()\n",
    "    # List of unique assets\n",
    "    assets = df[\"asset\"].unique()\n",
    "\n",
    "    # Create a DataFrame that includes all combinations for each asset\n",
    "    all_combinations = pd.DataFrame(\n",
    "        list(product(assets, activities, years)), columns=[\"asset\", \"activity\", \"year\"]\n",
    "    )\n",
    "\n",
    "    # Merge with original df to include counts\n",
    "    full_df = pd.merge(\n",
    "        all_combinations, df, on=[\"asset\", \"activity\", \"year\"], how=\"left\"\n",
    "    ).fillna(0)\n",
    "    full_df[\"totalCost\"] = full_df[\"totalCost\"].astype(float)\n",
    "\n",
    "    # Convert totalCost to millions\n",
    "    full_df[\"totalCost\"] = full_df[\"totalCost\"] / 1e6\n",
    "\n",
    "    # Create a pivot table for each asset\n",
    "    pivot_tables = {\n",
    "        asset: full_df[full_df[\"asset\"] == asset].pivot(\n",
    "            index=\"year\", columns=\"activity\", values=\"totalCost\"\n",
    "        )\n",
    "        for asset in assets\n",
    "    }\n",
    "\n",
    "    # Sort the pivot_tables dictionary by asset keys\n",
    "    pivot_tables = {asset: pivot_tables[asset] for asset in sorted(pivot_tables)}\n",
    "\n",
    "    # Determine the global min and max for the counts, to use in color scale normalization\n",
    "    vmin = min(pivot.min().min() for pivot in pivot_tables.values())\n",
    "    vmax = max(pivot.max().max() for pivot in pivot_tables.values())\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(\n",
    "        1, len(assets), sharey=True, gridspec_kw={\"wspace\": 0.1}, figsize=(14, 8)\n",
    "    )\n",
    "\n",
    "    cmap = sns.color_palette(\"rocket_r\", as_cmap=True)\n",
    "    cmap.set_bad(\"whitesmoke\")\n",
    "\n",
    "\n",
    "    # Plot each pivot table in a subplot\n",
    "    for i, (asset, pivot_table) in enumerate(pivot_tables.items()):\n",
    "        ax = axes[i]\n",
    "        pivot_table = pivot_table.replace(0, np.nan)\n",
    "        mask = pivot_table.isnull()\n",
    "        \n",
    "        # Create heatmap\n",
    "        sns.heatmap(\n",
    "            pivot_table,\n",
    "            ax=ax,\n",
    "            cbar=i == len(assets) - 1,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            cmap=cmap,\n",
    "            linewidth=4,\n",
    "            cbar_kws={\n",
    "                \"shrink\": 0.5, \n",
    "                \"label\": \"Total Cost ($M)\",\n",
    "                \"format\": \"%.1f\",\n",
    "                \"ticks\": plt.LinearLocator(6)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Set title (asset name)\n",
    "        ax.set_title(\"Asset \" + asset, fontsize=12, pad=20)\n",
    "        \n",
    "        # Configure y-axis (years)\n",
    "        ax.set_ylabel(\"Year\" if i == 0 else \"\", fontsize=12)  # Only show on first subplot\n",
    "        ax.yaxis.set_tick_params(labelsize=12, rotation=0)  # Horizontal year labels\n",
    "        \n",
    "        # Configure x-axis (activities)\n",
    "        ax.set_xlabel(\"Activity\", fontsize=12)\n",
    "        ax.xaxis.set_tick_params(labelsize=12, rotation=90)  # Vertical activity labels\n",
    "        \n",
    "        # If this is the last subplot (has colorbar)\n",
    "        if i == len(assets) - 1:\n",
    "            # Get the colorbar and adjust its properties\n",
    "            cbar = ax.collections[0].colorbar\n",
    "            cbar.ax.tick_params(labelsize=12)  # Set tick label size\n",
    "            cbar.ax.set_ylabel(\"Total Cost ($M)\", fontsize=12)  # Set label size\n",
    "\n",
    "    # Save plot if path is provided\n",
    "    if save_path:\n",
    "        if not save_path.endswith('.pdf'):\n",
    "            save_path += '.pdf'\n",
    "        \n",
    "        plt.savefig(\n",
    "            save_path,\n",
    "            format='pdf',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=0.1\n",
    "        )\n",
    "        print(f\"Plot saved as: {save_path}\")\n",
    "\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_query_6_heatmap(query=query_6, save_path='./assets/query_6_heatmap_plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ7. What are the cost implications of components participating in different states or processes?\n",
    "query_7 = '''\n",
    "MATCH p=(r:Record)-[:MENTIONS]->(m)-[ra:HAS_AGENT]-(n)<-[:MENTIONS]-(r)-[:MENTIONS]->(q)<-[rp:HAS_PATIENT]-(m)\n",
    "WHERE m.name CONTAINS 'leak' AND id(rp) IN r.relationIds AND id(ra) IN r.relationIds \n",
    "WITH r.floc AS system, m.name AS event, q.name AS substance, n.name AS component, COUNT(*) AS count, SUM(r.cost) AS totalCost\n",
    "WHERE totalCost > 5000\n",
    "RETURN system, component, event, substance, count, totalCost\n",
    "ORDER BY system, totalCost DESC\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_7_df = fetch_data(query=query_7)\n",
    "query_7_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Discovery and Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQ8. Provide a taxonomical breakdown of X. (X = engine)\n",
    "# Note: the return statement of this query has been modified to allow it be represented as a table. Replace it with `RETURN p` and execute within Neo4J to see the sugraph network.\n",
    "query_8 = '''\n",
    "MATCH p=(n)-[r:HAS_PART]->(m)\n",
    "WHERE labels(n)[0] CONTAINS 'Object' AND labels(m)[0] CONTAINS 'Object' AND n.name = 'engine' AND r.frequency > 1\n",
    "RETURN n.name AS component, m.name AS part, r.frequency AS count\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_8_df = fetch_data(query=query_8)\n",
    "# Show the top 25 rows\n",
    "query_8_df.head(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
